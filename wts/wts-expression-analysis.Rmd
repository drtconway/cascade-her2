---
title: "CASCADE HER2 Gene Expression Analysis"
author: "Thomas Conway"
date: "2020-05-11"
header-includes:
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage{xcolor}
output:
  html_document:
    toc: true
  pdf_document:
    keep_tex: true
---

# CASCADE HER2+ Gene Expression Analysis

The CASCADE project is a study across several cancer types, in which
in addition to any samples taken at diagnosis and during treatment,
at death, a rapid autopsy is performed to sample metastatic leisions
that may not be accessable otherwise. Among the various assays used, are
whole genome sequencing (WGS), and whole transcriptome sequencing (WTS).

Here we present the differential gene expression (DGE) analysis of the
4 metastatic sites sampled from patient CAS0057, who was diagnosed with
HER2+ breast cancer.

## Preamble

```{r, echo=FALSE}
library(data.table)
library(ggplot2)
library(scales)

library(EnsDb.Hsapiens.v75)
library(edgeR)
library(kableExtra)

gene.names <- select(EnsDb.Hsapiens.v75, keys=keys(EnsDb.Hsapiens.v75, keytype="GENEID"), keytype="GENEID", columns=c("GENEID", "GENENAME"))
gene.names <- data.table(ensembl.id = gene.names$GENEID, name = gene.names$GENENAME)
setkey(gene.names, 'ensembl.id')

commaize <- label_comma()
percentize <- label_percent()
boldize <- function(v) { text_spec(v, bold=TRUE) }
decimalize <- function(v) { sprintf("%2.2f", v) }

pam50.matrix <- fread('pam50_centroids.txt', header=TRUE);
pam50.long <- melt(pam50.matrix, id.vars='gene')[, .(gene, type = variable, weight = value)]

samples.toc <- fread('data/samples-toc.tsv', header=TRUE)
samples.toc[WGS.project == "NA",    WGS.project := NA]
samples.toc[WTS.project == "NA",    WTS.project := NA]
samples.toc[vcf.file == "NA",       vcf.file := NA]
samples.toc[counts.file == "NA",    counts.file := NA]

read.counts <- fread('data/read-counts.txt', header=TRUE)
setkey(read.counts, 'project')
```

```{r, echo=FALSE}
counts.wide.all <- data.table()

load.counts <- function(fn, pid, sid) {
    col.nms <- c('ensembl.id', paste0(pid, '.', sid))
    fd <- fread(paste0('data/', fn), col.names=col.nms)
    setkey(fd, 'ensembl.id')
    if (nrow(counts.wide.all) == 0) {
        counts.wide.all[, ensembl.id := fd$ensembl.id]
        setkey(counts.wide.all, 'ensembl.id')
    }
    stopifnot(counts.wide.all$ensembl.id == fd$ensembl.id)
    counts.wide.all[, (col.nms[2]) := fd[, 2]]
}

unused <- samples.toc[!is.na(counts.file), mapply(load.counts, counts.file, patient.id, sample.id)]

counts.wide <- counts.wide.all[grepl("^ENS", ensembl.id)]

counts.long.all <- melt(counts.wide.all, id.vars='ensembl.id')[, .(ensembl.id, sample = variable, count = value)]
counts.long.all[, patient.id := gsub("[.].*", "", sample)]
counts.long <- counts.long.all[grepl("^ENS", ensembl.id)]
```

## Basic data summary

The following samples underwent Whole Transcriptome Sequencing (WTS):

```{r, echo=FALSE}
x <- samples.toc
setkey(x, 'WTS.project')
x <- merge(x, read.counts, by.x='WTS.project', by.y='project')
setkeyv(x, c('patient.id', 'sample.id'))
knitr::kable(x[!is.na(WTS.project), .(patient.id, sample.id, WTS.project, read.count = commaize(read.count), sample.site)],
             caption="Data Summary")
```

The reader were aligned to hg19 with STAR, using Homo\_sapiens.GRCh37.87.gtf.
Using `htseq-count` to count the number of reads per gene, we get the following raw counts:

```{r, echo=FALSE, results='asis'}
alignment.summary <- counts.long.all[,
    .(fragments = sum(count),
      good.count = sum(grepl("^ENS", ensembl.id) * count),
      good.frac = sum(grepl("^ENS", ensembl.id) * count)/sum(count),
      no.feature = sum((ensembl.id == "__no_feature") * count)/sum(count),
      ambiguous = sum((ensembl.id == "__ambiguous") * count)/sum(count),
      non.unique = sum((ensembl.id == "__alignment_not_unique") * count)/sum(count)),
    by=.(patient.id, sample)]

for (pid in unique(alignment.summary$patient.id)) {
    print(knitr::kable(alignment.summary[patient.id == pid,
        .(sample,
          fragments = commaize(fragments),
          good.count = commaize(good.count),
          good.frac = percentize(good.frac),
          no.feature = percentize(no.feature),
          ambiguous = percentize(ambiguous),
          non.unique = percentize(non.unique)
        )], caption=paste0(pid, " alignment summary")))
}
```

The raw counts have the following distribution:

```{r, echo=FALSE}
ggplot(counts.long[count > 1], aes(log2(count))) +
    geom_density(aes(group=sample, fill=sample), alpha=0.25) +
    theme_minimal() +
    facet_wrap(~patient.id)
```

## PAM50 Classification

PAM50 classification was performed using the centroid matrix from
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6547580/ using the lcpm
values. The usual method was evaluated: using the Spearman's rank
correlation between the lcpm values and the centroid values.

```{r, echo=FALSE, cache=TRUE}
# Take a table of <name,lcpm> pairs and determine type type.
#
calc.pam50.type.inner <- function(lcpms) {
    y <- lcpms[, .(pam50.cor = cor(lcpm, weight, method="spearman")), by=.(type)]
    type.level <- y[, which.max(pam50.cor)]
    return(type.level)
}

# Take a table of <name,lcpm> pairs and determine type type.
#
calc.pam50.type <- function(lcpms) {
    x0 <- lcpms
    setkey(x0, 'name')
    x0 <- merge(x0, pam50.long, by.x='name', by.y='gene')
    t0 <- calc.pam50.type.inner(x0)
    tps <- pam50.long[gene=='ERBB2', type]
    tps[t0]
}

# Take a table of <name,lcpm> pairs and perturb it
#
add.noise <- function(lcpms, alpha) {
    lcpms[, .(name, weight, type, lcpm = lcpm + runif(length(lcpm), -alpha, alpha))]
}

# Run multiple trials adding noise and return the fraction of results
# that are consistent with the original lcpm values.
#
test.pam50 <- function(lcpms, alpha, n.reps) {
    x0 <- lcpms
    setkey(x0, 'name')
    x0 <- merge(x0, pam50.long, by.x='name', by.y='gene')
    t0 <- calc.pam50.type.inner(x0)
    tps <- pam50.long[gene=='ERBB2', type]
    res.tbl <- data.table(type=tps, count=rep(0, length(tps)))
    for (i in (1:n.reps)) {
        x <- add.noise(x0, alpha)
        t <- calc.pam50.type.inner(x)
        res.tbl[t, count := count + 1]
    }
    res.tbl[t0]$count / sum(res.tbl$count)
}

# Find the lowest noise level at which the consistency drops below 95%
#
find.noise.tolerance <- function(lcpms) {
    max.lcpm <- max(lcpms$lcpm)

    lo <- 0
    hi <- max.lcpm
    while (hi - lo > 0.05) {
        mid <- (hi + lo) / 2.0
        p <- test.pam50(lcpms, mid, 1000)
        if (p < 0.95) {
            hi = mid
        } else {
            lo = mid
        }
    }
    return(lo)
}

pam50.wrapper <- function(lcpms, names) {
    data.table(lcpm = lcpms, name = names)
}
lcpm.pam50 <- merge(lcpm.long, gene.names, by.x='ensembl.id', by.y='ensembl.id')[, .(patient.id, sample, name, lcpm)]
setkey(lcpm.pam50, 'name')
pam50.summary <- lcpm.pam50[, .(type = calc.pam50.type(pam50.wrapper(lcpm, name)),
                                tolerance.95 = find.noise.tolerance(pam50.wrapper(lcpm, name)),
                                consistency.1 = test.pam50(pam50.wrapper(lcpm, name), 1, 1000)), by=.(patient.id, sample)]
```

We have computed PAM50 types for all the samples.
Along with the PAM50 type, we report two measures that give an indication
of how reliable the computed type might be.  These two measures -
*tolerance* and *consistency* - are complementary in some sense.

Consistency is computed by performing repeated trials of adding a given
level of noise to the lcpm data and computing the result, then calculating
the proportion of results that agree with the result obtained without
adding noise. Note that because lcpm has a logarithmic relationship
to the original counts, adding noise corresponds to a multiplicative
effect on the counts.  Accordingly, adding noise in the range +/- 1,
corresponds to noise that scales the counts between half and double.

Tolerance is computed as the minimum amount of noise that must be added
to lcpm values to make the consistency drop below a given threshhold.
It is computed by evaluating the consistency in a binary search.

The table below shows the computed PAM50 types, along with the
consistency at a lcpm noise level of +/- 1, and the noise tolerance for
95% consistency.

```{r, echo=FALSE}
knitr::kable(pam50.summary[, .(patient.id, sample, type, consistency.1 = percentize(consistency.1), tolerance.95)], digits = 2) %>% collapse_rows(columns = 1, valign = "top")
```

## Highly Expressed Genes

There are a small number of genes with large counts. In order to
compare them across samples, we perform top-quartile normalisation after
discarding small counts (i.e. < 10), to yield counts per million (cpm)

```{r, echo=FALSE, results='asis'}
quant.summary <- counts.long[count >= 10,
    .(q25 = quantile(count, 0.25),
      q50 = quantile(count, 0.5),
      q75 = quantile(count, 0.75),
      sum.q75 = sum(count * (count > quantile(count, 0.75)))),
    by=.(patient.id, sample)]
quant.summary[, scaling.factor := 1e6/sum.q75]
for (pid in unique(quant.summary$patient.id)) {
    print(knitr::kable(quant.summary[patient.id == pid, .(sample, q25, q50, q75, sum.q75, scaling.factor)], caption=pid))
}
```

```{r, echo=FALSE}
cpm.long <- counts.long[, .(patient.id, sample, ensembl.id, cpm = (0.5 + count) * quant.summary[sample==sample, scaling.factor])]
lcpm.long <- cpm.long[, .(patient.id, sample, ensembl.id, lcpm = log2(cpm))]

ggplot(lcpm.long, aes(lcpm)) +
    geom_density(aes(group=sample, fill=sample), alpha=0.25) +
    theme_minimal() +
    facet_wrap(~patient.id)
```

Taking the most expressed 50 genes, we see the following relative expression across the different samples for each patient.

```{r, echo=FALSE, fig.align='center'}
# Pull out the list of most highly expressed genes
#
lcpm.of.interest <- lcpm.long[, .(lcpm = max(lcpm)), by=.(ensembl.id)]
setkey(lcpm.of.interest, 'lcpm')
high.genes = tail(lcpm.of.interest, 50)$ensembl.id

# Use them to extract a subset of the data
#
hgdt <- lcpm.long[ensembl.id %in% high.genes]
setkey(hgdt, 'ensembl.id')
hgdt <- merge(hgdt, gene.names, by.x='ensembl.id', by.y='ensembl.id')

# Order them by mean lcpm.
#
hg.order <- hgdt[, .(lcpm.mean = sum(lcpm)/length(lcpm)), by=.(name)]
setkey(hg.order, 'lcpm.mean')
hgdt[, name := factor(name, levels=hg.order$name)]

for (pid in unique(hgdt$patient.id)) {
    print(ggplot(hgdt[patient.id==pid], aes(name, lcpm, colour=sample)) +
                geom_point() +
                labs(x='gene', y='lcpm', colour='sample', title=pid) +
                theme_minimal() +
                theme(axis.text.x = element_text(size = 7, angle = 90, hjust = 1), legend.position = "bottom"))
}
```

Taking the 50 genes with the greatest absolute variance, we see the following relative expression across the different samples for each patient.


```{r, echo=FALSE, fig.align='center'}
# Pull out the list of most highly variable genes
#
lcpm.of.interest <- lcpm.long[, .(lcpm = var(lcpm)), by=.(ensembl.id)]
setkey(lcpm.of.interest, 'lcpm')
high.genes = tail(lcpm.of.interest, 50)$ensembl.id

# Use them to extract a subset of the data
#
hgdt <- lcpm.long[ensembl.id %in% high.genes]
setkey(hgdt, 'ensembl.id')
hgdt <- merge(hgdt, gene.names, by.x='ensembl.id', by.y='ensembl.id')

# Order them by mean lcpm.
#
hg.order <- hgdt[, .(lcpm.var = var(lcpm)), by=.(name)]
setkey(hg.order, 'lcpm.var')
hgdt[, name := factor(name, levels=hg.order$name)]

for (pid in unique(hgdt$patient.id)) {
    print(ggplot(hgdt[patient.id==pid], aes(name, lcpm, colour=sample)) +
                geom_point() +
                labs(x='gene', y='lcpm', colour='sample', title=pid) +
                theme_minimal() +
                theme(axis.text.x = element_text(size = 7, angle = 90, hjust = 1), legend.position = "bottom"))
}
```
